{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import codecs\n",
    "\n",
    "from konlpy.utils import pprint\n",
    "from konlpy.tag import *\n",
    "from konlpy.tag import Twitter, Komoran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with codecs.open(filename, encoding='utf-8', mode='r') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:] # remove header\n",
    "    return data\n",
    "\n",
    "train_data = read_data('./data/ratings_train.txt')\n",
    "test_data = read_data('./data/ratings_test.txt')\n",
    "\n",
    "# train data\n",
    "t1, t2, t3 = zip(*train_data) # python3 zip function() - return tuple, python2 zip function() - return list\n",
    "X_train = t2\n",
    "y_train = np.array(t3, dtype=int) # chage type string to integer\n",
    "\n",
    "# test data\n",
    "t1, t2, t3 = zip(*test_data) # python3 zip function() - return tuple, python2 zip function() - return list\n",
    "X_test = t2\n",
    "y_test = np.array(t3, dtype=int) # chage type string to integer\n",
    "\n",
    "# y data - 0 : negative, 1: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set Tarining Data, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, train_size=10000, test_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    result = ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "    return result\n",
    "\n",
    "clf_1 = Pipeline([\n",
    "            ('vect', CountVectorizer()), \n",
    "            ('clf', MultinomialNB()),\n",
    "        ])\n",
    "clf_2 = Pipeline([\n",
    "            ('vect', TfidfVectorizer()), \n",
    "            ('clf', MultinomialNB()),\n",
    "        ])\n",
    "clf_3 = Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))), \n",
    "            ('clf', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = clf_1.fit(X_train, y_train)\n",
    "model2 = clf_2.fit(X_train, y_train)\n",
    "model3 = clf_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Report Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        55\n",
      "          1       0.67      0.67      0.67        45\n",
      "\n",
      "avg / total       0.70      0.70      0.70       100\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.71      0.72        55\n",
      "          1       0.66      0.69      0.67        45\n",
      "\n",
      "avg / total       0.70      0.70      0.70       100\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.82      0.83        55\n",
      "          1       0.78      0.80      0.79        45\n",
      "\n",
      "avg / total       0.81      0.81      0.81       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model1.predict(X_test)))\n",
    "print(classification_report(y_test, model2.predict(X_test)))\n",
    "print(classification_report(y_test, model3.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
